## ğŸš€ä¸‹è½½
`
pip install nonpapy
`

## ğŸ‰å¿«é€Ÿå¼€å§‹
```python
import numpy as np
import nopapy as npp

x = np.array([1, 2, 3, 4, 5])
y = np.array([2, 4, 6, 8, 10])
ypred = npp.NWEstimate(x, y, 3.5) # supposed to be 7
print(ypred) # 6.910633194984344
```

## ğŸ¨å…¶ä»–åŠŸèƒ½æ¨¡å—
- kernel: æ”¯æŒå¤šç§å†…ç½®æ ¸å‡½æ•°ï¼ŒåŒæ—¶æ”¯æŒè‡ªå®šä¹‰æ ¸å‡½æ•°
- estimate: åŒ…å«å¤šç§éå‚æ•°ä¼°è®¡æ–¹æ³•ï¼Œå…è®¸è‡ªå®šä¹‰æ ¸å‡½æ•°ã€å…‰æ»‘å¸¦å®½ã€é˜¶æ•°
- regression: æä¾›å¤šç§å…‰æ»‘æ–¹æ³•è¿›è¡Œæ‰¹é‡é¢„æµ‹
- scikit_like: æ”¯æŒåƒscikit-learnå’ŒPyTorchç”Ÿæˆç‰¹å®šå‚æ•°çš„å›å½’å¯¹è±¡ï¼Œä¼ é€’è‡ªå˜é‡å³å¯è·å¾—é¢„æµ‹å€¼

## ğŸ°æ¡ˆä¾‹: Estimate & Regression
## æ¡ˆä¾‹1: Estimate
é¦–å…ˆï¼Œä½ éœ€è¦å¼•å…¥ä¸€äº›å¿…è¦çš„åº“ï¼ŒåŒ…æ‹¬numpyå’Œnopapyï¼Œè¿™é‡Œæˆ‘ä»¬åªéœ€è¦GaussainKernelå’ŒLPEstimateã€‚
å¦‚æœä½ è¿˜æƒ³ç»˜å›¾ï¼Œé‚£ä¹ˆä½ éœ€è¦å¼•å…¥matplotlibã€‚ 

ä¸ºäº†å¤ç°è¿™ä¸ªæ¡ˆä¾‹çš„ç»“æœï¼Œæˆ‘ä»¬å»ºè®®ä½ è®¾å®šç§å­ï¼Œå¹¶ä¸”è®¾å®šmatplotlibçš„æ ·å¼ã€‚
```python
import numpy as np
from nopapy import GaussianKernel, LPEstimate
import matplotlib.pyplot as plt

np.random.seed(0)
plt.style.use('seaborn') # do not delete this, plz:)
plt.style.use('tableau-colorblind10')
```

ç¬¬äºŒæ­¥ï¼Œæ„å»ºä¸€ä¸ªå‡½æ•°:
$$f(x) = 2 \sin(x) + x^{0.8}$$
å‡è®¾æˆ‘ä»¬çš„æ ·æœ¬æ¥è‡ªäºè¿™ä¸ªå‡½æ•°ï¼Œè‡ªå˜é‡çš„èŒƒå›´æ˜¯$[0, 5]$ï¼Œå› å˜é‡åˆ™æ˜¯$f(x)$çš„å€¼åŠ ä¸Šéšæœºå™ªå£°ã€‚ xs0ä»£è¡¨æˆ‘ä»¬æƒ³è¦ç”¨éå‚æ•°å›å½’æ–¹æ³•æ‹Ÿåˆçš„ç›®æ ‡ç‚¹ã€‚
```python
def f(x):
    return 2 * np.sin(x) + x ** 0.8

sample_number = 50
x = np.sort(np.random.rand(sample_number) * 5)
y = f(x) + np.random.normal(loc=0, scale=0.3, size=(sample_number,))
xs0 = np.arange(0, 5.01, 0.01)
```
ç°åœ¨æˆ‘ä»¬å°±å¯ä»¥è¿›è¡Œæ‹Ÿåˆäº†ï¼Œåœ¨è¿™é‡Œé‡‡ç”¨äº†GaussianKernelå’ŒLPEstimateï¼Œå¹¶ä¸”è®¾ç½®LPEstimateçš„é˜¶æ•°ä¸º2ã€‚
å®é™…ä¸Šï¼Œä½ å¯ä»¥è‡ªç”±é€‰æ‹©æ ¸å‡½æ•°å’Œå›å½’æ–¹æ³•ï¼Œå”¯ä¸€çš„åŒºåˆ«æ˜¯å…¶å®ƒå›å½’æ–¹æ³•ä¸éœ€è¦å‚æ•°pã€‚
```python
kernel = GaussianKernel; h = 1; method = LPEstimate; p = 2
y_pred = [method(x, y, x0, h, k=kernel, p=p) for x0 in xs0]
```
æœ€åä¸€æ­¥ï¼Œå°†ç»“æœç»˜åˆ¶å‡ºæ¥ï¼Œç»˜åˆ¶çš„ç»“æœåŒ…å«äº†æ ·æœ¬ç‚¹$(x, y)$ï¼Œå‡½æ•°$f(x)$ï¼Œä»¥åŠæˆ‘ä»¬çš„å›å½’å‡½æ•°$g(x)$ã€‚
```python
plt.scatter(x, y, alpha=0.5, label='sample', c='darkorange')
plt.plot(xs0, f(xs0), '--', label='truth')
plt.plot(xs0, y_pred, label='pred')
plt.title('h={}, Kernel={}'.format(h, kernel.__name__))
plt.legend(loc='best', frameon=True, framealpha=1, shadow=True)
plt.show()
# plt.savefig('./LPR.svg', dpi=2000)``
```
ç»˜åˆ¶çš„ç»“æœåº”è¯¥å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œä½ å¯ä»¥è°ƒæ•´å¸¦å®½ï¼Œæ›´æ¢æ ¸å‡½æ•°ï¼Œæ›´æ¢å›å½’æ–¹æ³•ï¼Œç”šè‡³æ˜¯è®¾å®šé˜¶æ•°æ¥è§‚å¯Ÿæ‹Ÿåˆæ•ˆæœçš„ä¸åŒã€‚

<div align="center">
    <img src="./pictures/LPR.svg" alt="LPR">
</div>

å¦å¤–ï¼Œåœ¨ä¸Šé¢çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä¼ é€’äº†æ‰€æœ‰å¯ä»¥ä¼ é€’çš„å‚æ•°ï¼Œå®é™…ä¸Šè®¸å¤šå‚æ•°éƒ½æœ‰é»˜è®¤å€¼ï¼Œå¿…é¡»è¦ä¼ é€’çš„å‚æ•°åªæœ‰ x/y/x0 ã€‚
ä¾‹å¦‚
`
y_pred = [method(x, y, x0) for x0 in xs0]
`
ã€‚ä¸‹é¢è¦ä»‹ç»çš„Regressionä¹Ÿæ‹¥æœ‰åŒæ ·çš„æ€§è´¨ï¼Œä½ å¯ä»¥çœç•¥æ‰é‚£äº›ä¸å¿…è¦çš„å‚æ•°ã€‚

## æ¡ˆä¾‹2: Regression
å…¶ä»–æ­¥éª¤å‡ ä¹æ˜¯ä¸€æ ·çš„ï¼Œä½†æ˜¯Regressionæ–¹æ³•çš„åŠŸèƒ½æ›´å¼ºå¤§ï¼Œå®ƒèƒ½åŒæ—¶é¢„æµ‹ä¸€ç³»åˆ—çš„ç›®æ ‡ç‚¹ã€‚
```python
import numpy as np
from nopapy import GaussianKernel, LPRegression
import matplotlib.pyplot as plt

np.random.seed(0)
plt.style.use('seaborn') # do not delete this, plz:)
plt.style.use('tableau-colorblind10')

def f(x):
    return 2 * np.sin(x) + x ** 0.8

sample_number = 50
x = np.sort(np.random.rand(sample_number) * 5)
y = f(x) + np.random.normal(loc=0, scale=0.3, size=(sample_number,))
xs0 = np.arange(0, 5.01, 0.01)

kernel = GaussianKernel; h = 1; method = LPRegression; p = 2
y_pred = LPRegression(x, y, xs0, h, k=kernel, p=p)

plt.scatter(x, y, alpha=0.5, label='sample', c='darkorange')
plt.plot(xs0, f(xs0), '--', label='truth')
plt.plot(xs0, y_pred, label='pred')
plt.title('h={}, Kernel={}'.format(h, kernel.__name__))
plt.legend(loc='best', frameon=True, framealpha=1, shadow=True)
plt.show()
# plt.savefig('./LPR.svg', dpi=2000)
```
### âš ï¸è­¦å‘Š
ä½ ä¹Ÿå¯ä»¥åƒä½¿ç”¨Estimateé‚£æ ·ä½¿ç”¨Regressionï¼Œä¹Ÿå°±æ˜¯åªç”¨Regressioné¢„æµ‹ä¸€ä¸ªç‚¹ï¼Œè¿™ä¸ä¼šä¸ºä»£ç çš„æ­£ç¡®æ€§å¸¦æ¥ä»»ä½•é—®é¢˜ã€‚
ä½†æ˜¯æˆ‘ä»¬å¼ºçƒˆä¸æ¨èè¿™ä¹ˆåšï¼Œå› ä¸ºè¿™ä¼šå¯¼è‡´ä¸€äº›æ€§èƒ½ä¸Šçš„é—®é¢˜ã€‚
å¦‚æœä½ å¿…é¡»è¿™ä¹ˆåšï¼Œé‚£ä¹ˆä½ ä¼šæ”¶åˆ°ä¸€ä¸ªè­¦å‘Šï¼š
```
UserWarning: LPRegression() expects xs0 to be np.ndarray or list.
Your code won't make any errors, but we still recommend that you use LPEstimate() instead.
warnings.warn(warn_msg) 
```

### â›”  åšå¥½åˆ«è¿™ä¹ˆåš...
ä½ å¯èƒ½ä¼šæƒ³ä½¿ç”¨éå‚æ•°å›å½’è¿›è¡Œå¤–æ¨é¢„æµ‹ï¼Œä½†æ˜¯è¿™å¹¶ä¸æ˜¯éå‚æ•°å›å½’çš„å…¸å‹åº”ç”¨åœºæ™¯ã€‚
æˆ‘ä»¬çš„ä»£ç ä¸­å¹¶æ²¡æœ‰å¯¹è¿™ç§è¡Œä¸ºä½œå‡ºç¦æ­¢ï¼Œå› ä¸ºæˆ‘ä»¬ä¸ç¡®å®šæ‚¨æ˜¯å¦çœŸçš„æƒ³è¿™ä¹ˆåšï¼Œä¾‹å¦‚ï¼š

<div align="center">
    <img src="./pictures/DONOT.svg" alt="DONOT">
</div>

å¯ä»¥å‘ç°ï¼Œé™¤äº†GaussianKernelä»¥å¤–çš„å›å½’æ–¹æ³•éƒ½å¤±æ•ˆäº†ï¼Œè¿™æ˜¯å› ä¸ºå®ƒä»¬éƒ½é—´æ¥ä½¿ç”¨åˆ°äº†ç¤ºæ€§å‡½æ•°$I(x)$ã€‚
è€ŒGaussianKernelçš„é¢„æµ‹ç»“æœä¹Ÿä¸å°½å¦‚äººæ„ï¼Œè¿™æ˜¯å› ä¸ºéå‚æ•°å›å½’é‡‡ç”¨çš„æ˜¯"å…‰æ»‘æ–¹æ³•"ï¼Œè¿™ç§æ–¹æ³•ä»…å¯¹å®šä¹‰åŸŸå†…$[min(x), max(x)]$çš„å€¼æœ‰æ•ˆã€‚

## ğŸ°æ¡ˆä¾‹: Kernel & Custom
## æ¡ˆä¾‹1: Kernel
æˆ‘ä»¬æä¾›äº†å¤šä¸ªç°æˆçš„æ ¸å‡½æ•°ï¼Œä½ å¯ä»¥ç›´æ¥å°†å®ƒä»¬ä½¿ç”¨åˆ°ç›¸åº”çš„ä¼°è®¡å’Œå›å½’æ–¹æ³•ä¸­ï¼ŒåŒæ—¶ï¼Œå®ƒä»¬ä¹Ÿå¯ä»¥å•ç‹¬ä½¿ç”¨ï¼Œè¿™å¯èƒ½å¯¹æ‚¨çš„ç§‘ç ”æœ‰æ‰€å¸®åŠ©ã€‚
æ‚¨å¯ä»¥ä½¿ç”¨ä»£ç 
`
npp.kernel.kernel.__all__
`
æ¥æŸ¥çœ‹æ‰€æœ‰çš„æ ¸å‡½æ•°ã€‚å®ƒä»¬çš„ä½¿ç”¨æ–¹å¼è¾ƒä¸ºçµæ´»ï¼Œä½ å¯ä»¥è‡ªç”±åœ°é€‰æ‹©ï¼šä¾‹å¦‚ä¼ é€’ç»™å®ƒä¸€ä¸ªæ ‡é‡æˆ–è€…arrayã€‚
```python
from nopapy import GaussianKernel
x = np.arange(-3, 3, 0.01)
y = GaussianKernel(x)
plt.plot(x, y)
plt.show()
```
<div align="center">
    <img src="./pictures/GaussianKernel.svg" alt="GaussianKernel">
</div>

## æ¡ˆä¾‹2: Custom

åŒæ—¶æˆ‘ä»¬ä¹Ÿæ”¯æŒæ‚¨è‡ªå®šä¹‰æ ¸å‡½æ•°ï¼Œæ ¸å‡½æ•°æ˜¯ä¸€ç±»å…·æœ‰ç‰¹æ®Šæ•°å­¦æ€§è´¨çš„å‡½æ•°ï¼Œä¸€èˆ¬æ¥è¯´å®ƒä»¬è¦æ»¡è¶³ä»¥ä¸‹çš„æ€§è´¨ï¼š

- éè´Ÿæ€§: $f(x) \geq 0$
- å¯¹ç§°æ€§: $E(x) =\int xK(x) dx=0$
- æ¦‚ç‡å¯†åº¦: $\int K(x) dx=1$
- æ–¹å·®ä¸ºæ­£: $D(x)=E(x^2)=\int x^2K(x) dx>0$

æ‚¨å®ç°çš„æ ¸å‡½æ•°$custom_kernel(x)$éœ€è¦æ»¡è¶³ä¸Šè¿°æ€§è´¨ï¼Œä¸€èˆ¬è€Œè¨€ï¼Œæ‚¨å¯ä»¥é€šè¿‡æœç´¢å¼•æ“æœç´¢æ„Ÿå…´è¶£çš„æ ¸å‡½æ•°ï¼Œå¹¶å°†å®ƒå®ç°ä¸ºPythonçš„å‡½æ•°ã€‚
æˆ‘ä»¬æä¾›äº†å‡½æ•°$I(x)$å¸®åŠ©æ‚¨å¿«é€Ÿå®ç°æ‚¨çš„æ ¸å‡½æ•°ï¼Œå¾ˆå¤šæ ¸å‡½æ•°éƒ½ä¾èµ–äºç¤ºæ€§å‡½æ•°ã€‚ä¾‹å¦‚ï¼š
```python
def EpanechnikovKernel(x):
    return EPANECHNIKOV_COEFFICIENT * (1 - np.power(x, 2)) * I(x)
```
PS: GaussianKernelæ˜¯ä¸ªä¾‹å¤–ï¼Œå®ƒæ‹¥æœ‰ä¼˜é›…çš„æ•°å­¦æ€§è´¨ã€‚

###ğŸ‘‰ æˆ‘çš„å‡½æ•°æ˜¯å¦æ­£ç¡®ï¼Ÿ
æˆ‘ä»¬è¿˜æä¾›äº†å‡½æ•°is_kernelç”¨äºæ£€æµ‹æ‚¨çš„æ ¸å‡½æ•°æ˜¯å¦æ­£ç¡®ï¼Œå®ƒä»¥ä¸€ä¸ªå‡½æ•°ä½œä¸ºè¾“å…¥ï¼Œè¾“å‡ºä¸€ä¸ªå¸ƒå°”å€¼ä½œä¸ºæ­£ç¡®ä¸å¦çš„æ ‡å¿—ã€‚
```python
ret = is_kernel(GaussianKernel)
print(ret) # True
```